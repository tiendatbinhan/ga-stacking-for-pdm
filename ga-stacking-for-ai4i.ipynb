{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d911e62",
   "metadata": {
    "id": "Ff-YU7IVXkqW",
    "papermill": {
     "duration": 0.011505,
     "end_time": "2024-12-16T03:42:13.388554",
     "exception": false,
     "start_time": "2024-12-16T03:42:13.377049",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "499a1329",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T03:42:13.413863Z",
     "iopub.status.busy": "2024-12-16T03:42:13.413449Z",
     "iopub.status.idle": "2024-12-16T03:42:16.724868Z",
     "shell.execute_reply": "2024-12-16T03:42:16.723716Z"
    },
    "id": "9RIwS4dBXoSe",
    "papermill": {
     "duration": 3.326239,
     "end_time": "2024-12-16T03:42:16.727658",
     "exception": false,
     "start_time": "2024-12-16T03:42:13.401419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Literal, Iterable, Union\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Sklearn model selection and metrics\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Sklearn base estimator and ensemble models\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.ensemble import StackingClassifier, StackingRegressor, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "\n",
    "# Sklearn classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c34afe7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T03:42:16.751780Z",
     "iopub.status.busy": "2024-12-16T03:42:16.751217Z",
     "iopub.status.idle": "2024-12-16T03:42:16.756386Z",
     "shell.execute_reply": "2024-12-16T03:42:16.755335Z"
    },
    "id": "DGPWRo_Cq_1R",
    "papermill": {
     "duration": 0.019349,
     "end_time": "2024-12-16T03:42:16.758584",
     "exception": false,
     "start_time": "2024-12-16T03:42:16.739235",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6058bd",
   "metadata": {
    "id": "AK_HYsWIXgMp",
    "papermill": {
     "duration": 0.010604,
     "end_time": "2024-12-16T03:42:16.779895",
     "exception": false,
     "start_time": "2024-12-16T03:42:16.769291",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Genetic Algorithm functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa16680",
   "metadata": {
    "id": "tN0weONzX6yt",
    "papermill": {
     "duration": 0.014648,
     "end_time": "2024-12-16T03:42:16.813531",
     "exception": false,
     "start_time": "2024-12-16T03:42:16.798883",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Initialize population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10761e24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T03:42:16.841343Z",
     "iopub.status.busy": "2024-12-16T03:42:16.840771Z",
     "iopub.status.idle": "2024-12-16T03:42:16.847867Z",
     "shell.execute_reply": "2024-12-16T03:42:16.846687Z"
    },
    "id": "L4WHXEsXXeBp",
    "papermill": {
     "duration": 0.021557,
     "end_time": "2024-12-16T03:42:16.850308",
     "exception": false,
     "start_time": "2024-12-16T03:42:16.828751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def initialize_population(num_individuals, num_variables, seed):\n",
    "    np.random.seed(seed)\n",
    "    pop = np.random.randint(2, size=(num_individuals, num_variables))\n",
    "    return pop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d18e1a",
   "metadata": {
    "id": "3zaUwZnVX-OW",
    "papermill": {
     "duration": 0.009905,
     "end_time": "2024-12-16T03:42:16.872585",
     "exception": false,
     "start_time": "2024-12-16T03:42:16.862680",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Crossover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ef667d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T03:42:16.895741Z",
     "iopub.status.busy": "2024-12-16T03:42:16.895353Z",
     "iopub.status.idle": "2024-12-16T03:42:16.904948Z",
     "shell.execute_reply": "2024-12-16T03:42:16.903768Z"
    },
    "id": "Iv6_Fhk9X90n",
    "papermill": {
     "duration": 0.023572,
     "end_time": "2024-12-16T03:42:16.907213",
     "exception": false,
     "start_time": "2024-12-16T03:42:16.883641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def crossover(pop, mode: Literal[\"1X\", \"UX\"] = \"UX\", seed=None, crossover_prob=0.5):\n",
    "    np.random.seed(seed)\n",
    "    num_individuals = len(pop)\n",
    "    num_parameters = len(pop[0])\n",
    "    indices = np.arange(num_individuals)\n",
    "    np.random.shuffle(indices)\n",
    "    offspring = []\n",
    "\n",
    "    for i in range(0, num_individuals, 2):\n",
    "        idx1 = indices[i]\n",
    "        idx2 = indices[i + 1]\n",
    "        offspring1 = list(pop[idx1])\n",
    "        offspring2 = list(pop[idx2])\n",
    "\n",
    "        if mode == \"UX\":\n",
    "            for idx in range(0, num_parameters):\n",
    "                r = np.random.rand()\n",
    "                if r < crossover_prob:\n",
    "                    temp = offspring2[idx]\n",
    "                    offspring2[idx] = offspring1[idx]\n",
    "                    offspring1[idx] = temp\n",
    "        else:\n",
    "            cross_point = np.random.randint(num_parameters - 1)\n",
    "            for idx in range(cross_point, num_parameters):\n",
    "                temp = offspring2[idx]\n",
    "                offspring2[idx] = offspring1[idx]\n",
    "                offspring1[idx] = temp\n",
    "\n",
    "        offspring.append(offspring1)\n",
    "        offspring.append(offspring2)\n",
    "\n",
    "    offspring = np.array(offspring)\n",
    "    return offspring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20a542b",
   "metadata": {
    "id": "qhp4XSA7YJ0l",
    "papermill": {
     "duration": 0.009958,
     "end_time": "2024-12-16T03:42:16.928558",
     "exception": false,
     "start_time": "2024-12-16T03:42:16.918600",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eabf4f74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T03:42:16.950315Z",
     "iopub.status.busy": "2024-12-16T03:42:16.949867Z",
     "iopub.status.idle": "2024-12-16T03:42:16.956396Z",
     "shell.execute_reply": "2024-12-16T03:42:16.955055Z"
    },
    "id": "J9v93kuIYHnY",
    "papermill": {
     "duration": 0.020004,
     "end_time": "2024-12-16T03:42:16.958696",
     "exception": false,
     "start_time": "2024-12-16T03:42:16.938692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mutation(pop, seed=None, mutation_prob=0.5):\n",
    "    np.random.seed(seed)\n",
    "    num_individuals = len(pop)\n",
    "    num_parameters = len(pop[0])\n",
    "\n",
    "    mutation_mask = np.random.choice([True, False],\n",
    "                                     size=(num_individuals, num_parameters),\n",
    "                                     p=[mutation_prob, 1 - mutation_prob])\n",
    "    return np.where(mutation_mask, 1-pop, pop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119237a8",
   "metadata": {
    "id": "gWpC934gYQd2",
    "papermill": {
     "duration": 0.009418,
     "end_time": "2024-12-16T03:42:16.979065",
     "exception": false,
     "start_time": "2024-12-16T03:42:16.969647",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "524f4309",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T03:42:17.000992Z",
     "iopub.status.busy": "2024-12-16T03:42:17.000538Z",
     "iopub.status.idle": "2024-12-16T03:42:17.010614Z",
     "shell.execute_reply": "2024-12-16T03:42:17.009110Z"
    },
    "id": "0ukfoMgFYNX_",
    "papermill": {
     "duration": 0.023823,
     "end_time": "2024-12-16T03:42:17.012821",
     "exception": false,
     "start_time": "2024-12-16T03:42:16.988998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tournament_selection_for_popop(pop, pop_fitness, tournament_size, seed=None):\n",
    "    assert pop.shape[0] == pop_fitness.shape[0]\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    selected_indices = []\n",
    "    indices = np.arange(pop.shape[0])\n",
    "\n",
    "    for _ in range(2):\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        tournament_groups = np.split(indices, np.arange(tournament_size, pop.shape[0], tournament_size))\n",
    "\n",
    "        for group in tournament_groups:\n",
    "            group_fitness = np.apply_along_axis(lambda x: pop_fitness[x], arr=group, axis=0)\n",
    "            selected_indices.append(group[np.argmax(group_fitness)])\n",
    "\n",
    "    selected_indices = np.array(selected_indices)\n",
    "    return selected_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "770149e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T03:42:17.034285Z",
     "iopub.status.busy": "2024-12-16T03:42:17.033848Z",
     "iopub.status.idle": "2024-12-16T03:42:17.040565Z",
     "shell.execute_reply": "2024-12-16T03:42:17.039280Z"
    },
    "id": "EznwDQcsYShO",
    "papermill": {
     "duration": 0.020299,
     "end_time": "2024-12-16T03:42:17.042948",
     "exception": false,
     "start_time": "2024-12-16T03:42:17.022649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def truncation_selection(pop, pop_fitness, selection_size=None):\n",
    "    assert pop.shape[0] == pop_fitness.shape[0]\n",
    "    if selection_size is None:\n",
    "        selection_size = pop.shape[0] // 2\n",
    "    selected_indices = np.argsort(pop_fitness)[-selection_size:]\n",
    "    return selected_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b97bab2",
   "metadata": {
    "id": "zq4k7b5uYY4e",
    "papermill": {
     "duration": 0.010891,
     "end_time": "2024-12-16T03:42:17.063881",
     "exception": false,
     "start_time": "2024-12-16T03:42:17.052990",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Some misc functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c10127b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T03:42:17.086783Z",
     "iopub.status.busy": "2024-12-16T03:42:17.086326Z",
     "iopub.status.idle": "2024-12-16T03:42:17.094291Z",
     "shell.execute_reply": "2024-12-16T03:42:17.092453Z"
    },
    "id": "CE89ys4XYUPg",
    "papermill": {
     "duration": 0.022967,
     "end_time": "2024-12-16T03:42:17.096922",
     "exception": false,
     "start_time": "2024-12-16T03:42:17.073955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def merge_two_population(pop1, pop2):\n",
    "    result_pop = np.vstack([pop1, pop2])\n",
    "    return result_pop\n",
    "\n",
    "def pop_from_selection(pop, selected_indices):\n",
    "    result_pop = np.array([pop[i] for i in selected_indices])\n",
    "    return result_pop\n",
    "\n",
    "def is_converged(pop: np.ndarray):\n",
    "    return np.unique(pop).shape[0] == 1\n",
    "\n",
    "def is_best_fitness_possible(pop: np.ndarray, best_fitness, func):\n",
    "    num_params = pop[0].shape[0]\n",
    "    best_ind = np.ones(num_params)\n",
    "    return best_fitness == func(best_ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b179028b",
   "metadata": {
    "id": "NpqxNpZ3YwjV",
    "papermill": {
     "duration": 0.010005,
     "end_time": "2024-12-16T03:42:17.116850",
     "exception": false,
     "start_time": "2024-12-16T03:42:17.106845",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Genetic Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c07bb3",
   "metadata": {
    "id": "7uub_gQ8Yy81",
    "papermill": {
     "duration": 0.009847,
     "end_time": "2024-12-16T03:42:17.136816",
     "exception": false,
     "start_time": "2024-12-16T03:42:17.126969",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Paper-purposed algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a85ae34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T03:42:17.159917Z",
     "iopub.status.busy": "2024-12-16T03:42:17.159489Z",
     "iopub.status.idle": "2024-12-16T03:42:17.171820Z",
     "shell.execute_reply": "2024-12-16T03:42:17.170198Z"
    },
    "id": "dU3_bFdsYvTg",
    "papermill": {
     "duration": 0.026863,
     "end_time": "2024-12-16T03:42:17.174125",
     "exception": false,
     "start_time": "2024-12-16T03:42:17.147262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def paper_genetic_algorithm(fitness_function: callable,\n",
    "                            num_individuals: int,\n",
    "                            num_parameters: int,\n",
    "                            seed=None,\n",
    "                            num_generations: int=10,\n",
    "                            mutation_rate: float=0.5,\n",
    "                            crossover_rate: float=0.5,\n",
    "                            verbose=False):\n",
    "    # Step 1: Initialize Population\n",
    "    population = initialize_population(num_individuals, num_parameters, seed)\n",
    "    gen_counter = 0\n",
    "    eval_counter = 0\n",
    "    best_fitness = []\n",
    "    fitness_scores = None  # Initialize fitness_scores as None\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Gen #{gen_counter}:\\n{population}\")\n",
    "\n",
    "    # Step 2: Evolutionary loop\n",
    "    for generation in range(num_generations):\n",
    "        # Step 3: Evaluation (only if fitness_scores is None)\n",
    "        if fitness_scores is None:\n",
    "            fitness_scores = np.array([fitness_function(individual) for individual in population])\n",
    "            eval_counter += fitness_scores.shape[0]\n",
    "\n",
    "        gen_counter += 1\n",
    "        best_fitness.append([eval_counter, np.max(fitness_scores)])\n",
    "\n",
    "        # Step 4: Selection\n",
    "        selected_individuals = truncation_selection(population, fitness_scores)\n",
    "        selected_population = pop_from_selection(population, selected_individuals)\n",
    "        selected_fitness_scores = fitness_scores[selected_individuals]  # Extract fitness scores for selected individuals\n",
    "\n",
    "        # Step 5: Crossover\n",
    "        offspring = crossover(population, crossover_prob=crossover_rate)\n",
    "\n",
    "        # Step 6: Mutation\n",
    "        mutated_offspring = mutation(offspring, mutation_prob=mutation_rate)\n",
    "        offspring_fitness_scores = np.array([fitness_function(individual) for individual in mutated_offspring])\n",
    "        eval_counter += offspring_fitness_scores.shape[0]\n",
    "\n",
    "        mutated_selection = truncation_selection(mutated_offspring, offspring_fitness_scores)\n",
    "        mutated_offspring = pop_from_selection(mutated_offspring, mutated_selection)\n",
    "        selected_offspring_fitness_scores = offspring_fitness_scores[mutated_selection]  # Extract fitness scores for mutated selection\n",
    "\n",
    "        # Step 7: Create new population\n",
    "        population = merge_two_population(selected_population, mutated_offspring)\n",
    "        fitness_scores = np.concatenate((selected_fitness_scores, selected_offspring_fitness_scores))  # Merge fitness scores\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Gen #{gen_counter}:\\n{population}\")\n",
    "\n",
    "        # Step 8: Check for convergence\n",
    "        if is_converged(population):\n",
    "            break\n",
    "\n",
    "    if verbose:\n",
    "        print('#Final result:')\n",
    "        print(population)\n",
    "        print(best_fitness)\n",
    "\n",
    "    return (population,\n",
    "            fitness_scores,\n",
    "            best_fitness,\n",
    "            eval_counter,\n",
    "            is_converged(population),\n",
    "            is_best_fitness_possible(population, np.max(fitness_scores), fitness_function))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38248d8",
   "metadata": {
    "id": "YKEGyUI0Y6qN",
    "papermill": {
     "duration": 0.00992,
     "end_time": "2024-12-16T03:42:17.194474",
     "exception": false,
     "start_time": "2024-12-16T03:42:17.184554",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## POPOP algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "183770c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T03:42:17.216092Z",
     "iopub.status.busy": "2024-12-16T03:42:17.215679Z",
     "iopub.status.idle": "2024-12-16T03:42:17.225800Z",
     "shell.execute_reply": "2024-12-16T03:42:17.224697Z"
    },
    "id": "UraP-l6LY6PU",
    "papermill": {
     "duration": 0.023971,
     "end_time": "2024-12-16T03:42:17.228120",
     "exception": false,
     "start_time": "2024-12-16T03:42:17.204149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def popop_genetic_algorithm(metric, num_individuals, num_parameters,\n",
    "                            crossover_mode: Literal[\"1X\", \"UX\"] = \"UX\",\n",
    "                            max_evaluations=100_000, seed=None, verbose=False,\n",
    "                            crossover_prob=0.5, mutation_prob=0.1):\n",
    "    pop = initialize_population(num_individuals, num_parameters, seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    num_eval = 0\n",
    "    generation_num = 0\n",
    "    best_fitness = []\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Gen #0:\\n{pop}\")\n",
    "\n",
    "    while num_eval < max_evaluations:\n",
    "        offspring = crossover(pop, crossover_mode, seed, crossover_prob=crossover_prob)\n",
    "        offspring = mutation(offspring, seed, mutation_prob=mutation_prob)\n",
    "        pop = merge_two_population(pop, offspring)\n",
    "\n",
    "        pop_fitness = np.array([metric(ind) for ind in pop])\n",
    "        num_eval += pop_fitness.shape[0]\n",
    "        best_fitness.append([num_eval, np.max(pop_fitness)])\n",
    "\n",
    "        selection_indices = tournament_selection_for_popop(pop, pop_fitness, 4, seed)\n",
    "        pop = pop_from_selection(pop, selection_indices)\n",
    "        generation_num += 1\n",
    "        if verbose:\n",
    "            print(f\"Gen #{generation_num}:\\n{pop}\")\n",
    "\n",
    "        if is_converged(pop):\n",
    "            break\n",
    "\n",
    "    pop_fitness = np.array([metric(ind) for ind in pop])\n",
    "    best_fitness.append([num_eval, np.max(pop_fitness)])\n",
    "    if verbose:\n",
    "        print('#Final result:')\n",
    "        print(pop)\n",
    "        print(pop_fitness)\n",
    "\n",
    "    return (pop,\n",
    "            pop_fitness,\n",
    "            best_fitness,\n",
    "            num_eval,\n",
    "            is_converged(pop),\n",
    "            is_best_fitness_possible(pop, np.max(pop_fitness), metric))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a9fccc",
   "metadata": {
    "id": "EKn9W9MoZBrH",
    "papermill": {
     "duration": 0.010002,
     "end_time": "2024-12-16T03:42:17.248412",
     "exception": false,
     "start_time": "2024-12-16T03:42:17.238410",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Tuning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97fb463c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T03:42:17.270673Z",
     "iopub.status.busy": "2024-12-16T03:42:17.270279Z",
     "iopub.status.idle": "2024-12-16T03:42:17.284762Z",
     "shell.execute_reply": "2024-12-16T03:42:17.283569Z"
    },
    "id": "pabDOPuBZBRP",
    "papermill": {
     "duration": 0.028731,
     "end_time": "2024-12-16T03:42:17.286995",
     "exception": false,
     "start_time": "2024-12-16T03:42:17.258264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from copy import deepcopy\n",
    "\n",
    "def tune_and_evaluate_models(X_train, X_val, y_train, y_val, base_models, tuning_params, metric, mode='auto', n_iter=20, cv=5, seed=None):\n",
    "    \"\"\"\n",
    "    Tune and evaluate models using GridSearchCV or RandomizedSearchCV based on the specified mode.\n",
    "\n",
    "    Parameters:\n",
    "    - X_train, X_val: Training and validation features\n",
    "    - y_train, y_val: Training and validation targets\n",
    "    - base_models: Dictionary of models to evaluate\n",
    "    - tuning_params: Dictionary of hyperparameter grids for tuning\n",
    "    - metric: Evaluation metric\n",
    "    - mode: 'exhaustive', 'grid', 'randomized', or 'auto'\n",
    "    - n_iter: Number of iterations for RandomizedSearchCV, or number of max iterations for 'auto'\n",
    "    - cv: Cross-validation strategy or number of folds\n",
    "\n",
    "    Returns:\n",
    "    - optimal_models: Dictionary of models fitted with the best parameters\n",
    "    - validation_performance: Dictionary of performance metrics and best parameters\n",
    "    \"\"\"\n",
    "    # Create a scorer from the metric (e.g., f1_score)\n",
    "    scorer = make_scorer(metric)\n",
    "\n",
    "    # Dictionary to store models with optimal parameters\n",
    "    optimal_models = {}\n",
    "    # Dictionary to store model performance on validation set\n",
    "    validation_performance = {}\n",
    "\n",
    "    # Iterate through each model in the base_models dictionary\n",
    "    for model_name, model in tqdm(base_models.items(), desc=\"Tuning Models\", unit=\"model\"):\n",
    "        # Make a deepcopy of the model to avoid altering the original\n",
    "        model_copy = deepcopy(model)\n",
    "\n",
    "        # Check if the model has tuning parameters provided in tuning_params\n",
    "        if model_name in tuning_params:\n",
    "            param_grid = tuning_params[model_name]\n",
    "\n",
    "            # Determine the total number of parameter combinations\n",
    "            num_combinations = np.prod([len(values) for values in param_grid.values()])\n",
    "\n",
    "            # Decide search method based on mode\n",
    "            if mode in ['exhaustive', 'grid']:\n",
    "                search_method = GridSearchCV\n",
    "                search_kwargs = {'param_grid': param_grid}\n",
    "            elif mode == 'randomized':\n",
    "                search_method = RandomizedSearchCV\n",
    "                search_kwargs = {'param_distributions': param_grid, 'n_iter': n_iter}\n",
    "            elif mode == 'auto':\n",
    "                if num_combinations <= n_iter:\n",
    "                    search_method = GridSearchCV\n",
    "                    search_kwargs = {'param_grid': param_grid}\n",
    "                else:\n",
    "                    search_method = RandomizedSearchCV\n",
    "                    search_kwargs = {'param_distributions': param_grid, 'n_iter': min(n_iter, num_combinations), 'random_state': seed}\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown mode '{mode}'. Choose from 'exhaustive', 'grid', 'randomized', 'auto'.\")\n",
    "\n",
    "            # Initialize the chosen search method with cross-validation\n",
    "            grid_or_random_search = search_method(\n",
    "                estimator=model_copy,\n",
    "                scoring=scorer,\n",
    "                cv=cv,\n",
    "                n_jobs=-1,\n",
    "                **search_kwargs\n",
    "            )\n",
    "\n",
    "            # Fit the model to the training data\n",
    "            grid_or_random_search.fit(X_train, y_train)\n",
    "\n",
    "            # Extract the best model and its parameters\n",
    "            best_params = grid_or_random_search.best_params_\n",
    "            best_score = grid_or_random_search.best_score_\n",
    "\n",
    "            # Equip the original model with the best parameters\n",
    "            best_model = clone(model)\n",
    "            best_model.set_params(**best_params)\n",
    "\n",
    "            # Fit the model with the optimal parameters\n",
    "            best_model.fit(X_train, y_train)\n",
    "\n",
    "            # Store the fitted model\n",
    "            optimal_models[model_name] = best_model\n",
    "\n",
    "            # Evaluate model performance on the validation set\n",
    "            val_score = metric(y_val, best_model.predict(X_val))\n",
    "            validation_performance[model_name] = {\n",
    "                \"best_params\": best_params,\n",
    "                \"cv_best_score\": best_score,\n",
    "                \"val_score\": val_score\n",
    "            }\n",
    "        else:\n",
    "            # If no tuning params are provided, use the model as is\n",
    "            model_copy.fit(X_train, y_train)\n",
    "\n",
    "            # Store the fitted model\n",
    "            optimal_models[model_name] = model_copy\n",
    "\n",
    "            # Evaluate on validation set without tuning\n",
    "            val_score = metric(y_val, model_copy.predict(X_val))\n",
    "            validation_performance[model_name] = {\n",
    "                \"best_params\": None,\n",
    "                \"cv_best_score\": None,\n",
    "                \"val_score\": val_score\n",
    "            }\n",
    "\n",
    "    return optimal_models, validation_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc9bf42",
   "metadata": {
    "id": "CQg09Es8ZO39",
    "papermill": {
     "duration": 0.009443,
     "end_time": "2024-12-16T03:42:17.306360",
     "exception": false,
     "start_time": "2024-12-16T03:42:17.296917",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GA-stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e34e15a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T03:42:17.328523Z",
     "iopub.status.busy": "2024-12-16T03:42:17.328102Z",
     "iopub.status.idle": "2024-12-16T03:42:17.346843Z",
     "shell.execute_reply": "2024-12-16T03:42:17.345575Z"
    },
    "id": "NSqDw_H4ZNpg",
    "papermill": {
     "duration": 0.032491,
     "end_time": "2024-12-16T03:42:17.349149",
     "exception": false,
     "start_time": "2024-12-16T03:42:17.316658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GAStackingSolver:\n",
    "    def __init__(self, X_train, y_train, X_val, y_val,\n",
    "                 base_models: Union[list[BaseEstimator], dict[str, BaseEstimator]],\n",
    "                 meta_model: BaseEstimator,\n",
    "                 num_individuals, metric,\n",
    "                 metric_mode: Literal['error', 'accuracy'] = 'accuracy',\n",
    "                 task: Literal['regressor', 'classifier'] = 'classifier',\n",
    "                 ga_mode: Literal['paper', 'popop'] = 'paper',\n",
    "                 max_gen=10,\n",
    "                 crossover_prob=0.2,\n",
    "                 mutation_prob=0.2,\n",
    "                 verbose=False,\n",
    "                 seed=None,\n",
    "                 **kwargs):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.num_individuals = num_individuals\n",
    "        self.metric = metric\n",
    "        self.metric_mode = metric_mode\n",
    "        self.task = task\n",
    "        self.ga_mode = ga_mode\n",
    "        self.max_gen = max_gen\n",
    "        self.crossover_prob = crossover_prob\n",
    "        self.mutation_prob = mutation_prob\n",
    "        self.verbose = verbose\n",
    "        self.seed = seed\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "        self.best_model = None\n",
    "        self.best_fitness = -np.inf if metric_mode == 'accuracy' else np.inf\n",
    "        self.best_combination = None\n",
    "\n",
    "    def _fitness(self, ind: np.ndarray):\n",
    "        num_params = ind.shape[0]\n",
    "\n",
    "        # Prepare base models based on the individual's chromosome\n",
    "        if isinstance(self.base_models, dict):\n",
    "            base_models_copy = [\n",
    "                (name, deepcopy(model)) for i, (name, model) in enumerate(self.base_models.items()) if ind[i]\n",
    "            ]\n",
    "        else:  # self.base_models is assumed to be a list\n",
    "            base_models_copy = [\n",
    "                (f\"estimator_{i}\", deepcopy(self.base_models[i])) for i in range(num_params) if ind[i]\n",
    "            ]\n",
    "\n",
    "        # Ensure we don't end up with an empty base model list\n",
    "        if not base_models_copy:\n",
    "            return -np.inf if self.metric_mode == 'accuracy' else np.inf\n",
    "\n",
    "        meta_model_copy = deepcopy(self.meta_model)\n",
    "        if self.task == 'classifier':\n",
    "            model = StackingClassifier(estimators=base_models_copy, final_estimator=meta_model_copy, cv='prefit', **self.kwargs)\n",
    "        else:\n",
    "            model = StackingRegressor(estimators=base_models_copy, final_estimator=meta_model_copy, cv='prefit', **self.kwargs)\n",
    "\n",
    "        model.fit(self.X_train, self.y_train)\n",
    "        y_val_predict = model.predict(self.X_val)\n",
    "        fitness_value = self.metric(self.y_val, y_val_predict)\n",
    "\n",
    "        if self.metric_mode == 'accuracy':\n",
    "            if fitness_value > self.best_fitness:\n",
    "                self.best_fitness = fitness_value\n",
    "                self.best_model = model\n",
    "                self.best_combination = np.copy(ind)\n",
    "        else:\n",
    "            if fitness_value < self.best_fitness:\n",
    "                self.best_fitness = fitness_value\n",
    "                self.best_model = model\n",
    "                self.best_combination = np.copy(ind)\n",
    "\n",
    "        return fitness_value if self.metric_mode == 'accuracy' else -fitness_value\n",
    "\n",
    "    def solve(self):\n",
    "        if self.ga_mode == 'popop':\n",
    "            return popop_genetic_algorithm(\n",
    "                self._fitness, self.num_individuals, len(self.base_models),\n",
    "                max_evaluations=self.max_gen * 2 * self.num_individuals,\n",
    "                crossover_prob=self.crossover_prob,\n",
    "                mutation_prob=self.mutation_prob,\n",
    "                verbose=self.verbose,\n",
    "                seed=self.seed\n",
    "            )\n",
    "        else:\n",
    "            return paper_genetic_algorithm(\n",
    "                self._fitness, self.num_individuals, len(self.base_models),\n",
    "                num_generations=self.max_gen,\n",
    "                crossover_rate=self.crossover_prob,\n",
    "                mutation_rate=self.mutation_prob,\n",
    "                verbose=self.verbose,\n",
    "                seed=self.seed\n",
    "            )\n",
    "\n",
    "def ga_stacking(X_train, y_train, X_val, y_val,\n",
    "                base_models: Union[list[BaseEstimator], dict[str, BaseEstimator]],\n",
    "                meta_model: BaseEstimator,\n",
    "                num_individuals, metric,\n",
    "                metric_mode: Literal['error', 'accuracy'] = 'accuracy',\n",
    "                task: Literal['regressor', 'classifier'] = 'classifier',\n",
    "                ga_mode: Literal['paper', 'popop'] = 'paper',\n",
    "                max_gen=10,\n",
    "                crossover_prob=0.2,\n",
    "                mutation_prob=0.2,\n",
    "                verbose=False,\n",
    "                seed=None,\n",
    "                **kwargs):\n",
    "    return GAStackingSolver(X_train, y_train, X_val, y_val,\n",
    "                            base_models,\n",
    "                            meta_model,\n",
    "                            num_individuals, metric,\n",
    "                            metric_mode,\n",
    "                            task,\n",
    "                            ga_mode,\n",
    "                            max_gen,\n",
    "                            crossover_prob,\n",
    "                            mutation_prob,\n",
    "                            verbose,\n",
    "                            seed,\n",
    "                            **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522fffd6",
   "metadata": {
    "id": "EM7cs3bxZevt",
    "papermill": {
     "duration": 0.010527,
     "end_time": "2024-12-16T03:42:17.370188",
     "exception": false,
     "start_time": "2024-12-16T03:42:17.359661",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfee4d91",
   "metadata": {
    "id": "mYlxZZwfbl5a",
    "papermill": {
     "duration": 0.010384,
     "end_time": "2024-12-16T03:42:17.391066",
     "exception": false,
     "start_time": "2024-12-16T03:42:17.380682",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Install AI4I 2020 PdM dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "413dcca9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T03:42:17.413831Z",
     "iopub.status.busy": "2024-12-16T03:42:17.413459Z",
     "iopub.status.idle": "2024-12-16T03:42:30.972072Z",
     "shell.execute_reply": "2024-12-16T03:42:30.970693Z"
    },
    "id": "Xp3zB8riZaLW",
    "outputId": "fcc4ddf5-419b-4dc3-a186-e6de39988677",
    "papermill": {
     "duration": 13.573375,
     "end_time": "2024-12-16T03:42:30.974869",
     "exception": false,
     "start_time": "2024-12-16T03:42:17.401494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ucimlrepo\r\n",
      "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\r\n",
      "Requirement already satisfied: pandas>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ucimlrepo) (2.2.3)\r\n",
      "Requirement already satisfied: certifi>=2020.12.5 in /opt/conda/lib/python3.10/site-packages (from ucimlrepo) (2024.6.2)\r\n",
      "Requirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.0->ucimlrepo) (1.26.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.0->ucimlrepo) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.0->ucimlrepo) (2024.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\r\n",
      "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\r\n",
      "Installing collected packages: ucimlrepo\r\n",
      "Successfully installed ucimlrepo-0.0.7\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec83ca6f",
   "metadata": {
    "id": "TuCdLooSdvDY",
    "papermill": {
     "duration": 0.009872,
     "end_time": "2024-12-16T03:42:30.995043",
     "exception": false,
     "start_time": "2024-12-16T03:42:30.985171",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Fetch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4af2e30d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T03:42:31.019221Z",
     "iopub.status.busy": "2024-12-16T03:42:31.018827Z",
     "iopub.status.idle": "2024-12-16T03:42:31.504138Z",
     "shell.execute_reply": "2024-12-16T03:42:31.502889Z"
    },
    "id": "gRYV6YujbsvM",
    "papermill": {
     "duration": 0.500025,
     "end_time": "2024-12-16T03:42:31.506813",
     "exception": false,
     "start_time": "2024-12-16T03:42:31.006788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# fetch dataset\n",
    "ai4i_2020_predictive_maintenance_dataset = fetch_ucirepo(id=601)\n",
    "\n",
    "# data (as pandas dataframes)\n",
    "X = ai4i_2020_predictive_maintenance_dataset.data.features\n",
    "y = ai4i_2020_predictive_maintenance_dataset.data.targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bebb43",
   "metadata": {
    "id": "bJaSJuZRdxKn",
    "papermill": {
     "duration": 0.010162,
     "end_time": "2024-12-16T03:42:31.527319",
     "exception": false,
     "start_time": "2024-12-16T03:42:31.517157",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Get metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7140365e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T03:42:31.549567Z",
     "iopub.status.busy": "2024-12-16T03:42:31.549145Z",
     "iopub.status.idle": "2024-12-16T03:42:31.560305Z",
     "shell.execute_reply": "2024-12-16T03:42:31.558874Z"
    },
    "id": "3oNAhQbVbxOz",
    "outputId": "dd3606ac-b137-4fc7-9bec-4e65c00d2cc4",
    "papermill": {
     "duration": 0.025135,
     "end_time": "2024-12-16T03:42:31.562787",
     "exception": false,
     "start_time": "2024-12-16T03:42:31.537652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'uci_id': 601,\n",
       " 'name': 'AI4I 2020 Predictive Maintenance Dataset',\n",
       " 'repository_url': 'https://archive.ics.uci.edu/dataset/601/ai4i+2020+predictive+maintenance+dataset',\n",
       " 'data_url': 'https://archive.ics.uci.edu/static/public/601/data.csv',\n",
       " 'abstract': 'The AI4I 2020 Predictive Maintenance Dataset is a synthetic dataset that reflects real predictive maintenance data encountered in industry.',\n",
       " 'area': 'Computer Science',\n",
       " 'tasks': ['Classification', 'Regression', 'Causal-Discovery'],\n",
       " 'characteristics': ['Multivariate', 'Time-Series'],\n",
       " 'num_instances': 10000,\n",
       " 'num_features': 6,\n",
       " 'feature_types': ['Real'],\n",
       " 'demographics': [],\n",
       " 'target_col': ['Machine failure', 'TWF', 'HDF', 'PWF', 'OSF', 'RNF'],\n",
       " 'index_col': ['UID', 'Product ID'],\n",
       " 'has_missing_values': 'no',\n",
       " 'missing_values_symbol': None,\n",
       " 'year_of_dataset_creation': 2020,\n",
       " 'last_updated': 'Wed Feb 14 2024',\n",
       " 'dataset_doi': '10.24432/C5HS5C',\n",
       " 'creators': [],\n",
       " 'intro_paper': {'ID': 386,\n",
       "  'type': 'NATIVE',\n",
       "  'title': 'Explainable Artificial Intelligence for Predictive Maintenance Applications',\n",
       "  'authors': 'S. Matzka',\n",
       "  'venue': 'International Conference on Artificial Intelligence for Industries',\n",
       "  'year': 2020,\n",
       "  'journal': None,\n",
       "  'DOI': '10.1109/AI4I49448.2020.00023',\n",
       "  'URL': 'https://www.semanticscholar.org/paper/b609c8e9ec6a2b8c642810953ef6dffe5766f7c1',\n",
       "  'sha': None,\n",
       "  'corpus': None,\n",
       "  'arxiv': None,\n",
       "  'mag': None,\n",
       "  'acl': None,\n",
       "  'pmid': None,\n",
       "  'pmcid': None},\n",
       " 'additional_info': {'summary': 'Since real predictive maintenance datasets are generally difficult to obtain and in particular difficult to publish, we present and provide a synthetic dataset that reflects real predictive maintenance encountered in industry to the best of our knowledge.\\r\\n\\r\\n\\r\\n\\r\\n',\n",
       "  'purpose': None,\n",
       "  'funded_by': None,\n",
       "  'instances_represent': None,\n",
       "  'recommended_data_splits': None,\n",
       "  'sensitive_data': None,\n",
       "  'preprocessing_description': None,\n",
       "  'variable_info': \"The dataset consists of 10 000 data points stored as rows with 14 features in columns\\r\\nUID: unique identifier ranging from 1 to 10000\\r\\nproduct ID: consisting of a letter L, M, or H for low (50% of all products), medium (30%) and high (20%) as product quality variants and a variant-specific serial number\\r\\nair temperature [K]: generated using a random walk process later normalized to a standard deviation of 2 K around 300 K\\r\\nprocess temperature [K]: generated using a random walk process normalized to a standard deviation of 1 K, added to the air temperature plus 10 K.\\r\\nrotational speed [rpm]: calculated from a power of 2860 W, overlaid with a normally distributed noise\\r\\ntorque [Nm]: torque values are normally distributed around 40 Nm with a Ïƒ = 10 Nm and no negative values. \\r\\ntool wear [min]: The quality variants H/M/L add 5/3/2 minutes of tool wear to the used tool in the process. and a\\r\\n'machine failure' label that indicates, whether the machine has failed in this particular datapoint for any of the following failure modes are true.\\r\\n\\r\\nThe machine failure consists of five independent failure modes\\r\\ntool wear failure (TWF): the tool will be replaced of fail at a randomly selected tool wear time between 200 â€“ 240 mins (120 times in our dataset). At this point in time, the tool is replaced 69 times, and fails 51 times (randomly assigned).\\r\\nheat dissipation failure (HDF): heat dissipation causes a process failure, if the difference between air- and process temperature is below 8.6 K and the toolâ€™s rotational speed is below 1380 rpm. This is the case for 115 data points.\\r\\npower failure (PWF): the product of torque and rotational speed (in rad/s) equals the power required for the process. If this power is below 3500 W or above 9000 W, the process fails, which is the case 95 times in our dataset.\\r\\noverstrain failure (OSF): if the product of tool wear and torque exceeds 11,000 minNm for the L product variant (12,000 M, 13,000 H), the process fails due to overstrain. This is true for 98 datapoints.\\r\\nrandom failures (RNF): each process has a chance of 0,1 % to fail regardless of its process parameters. This is the case for only 5 datapoints, less than could be expected for 10,000 datapoints in our dataset.\\r\\n\\r\\nIf at least one of the above failure modes is true, the process fails and the 'machine failure' label is set to 1. It is therefore not transparent to the machine learning method, which of the failure modes has caused the process to fail \",\n",
       "  'citation': None}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# metadata\n",
    "ai4i_2020_predictive_maintenance_dataset.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5870ea7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T03:42:31.585730Z",
     "iopub.status.busy": "2024-12-16T03:42:31.585319Z",
     "iopub.status.idle": "2024-12-16T03:42:31.603107Z",
     "shell.execute_reply": "2024-12-16T03:42:31.602028Z"
    },
    "id": "_qZeEI-pbzP4",
    "outputId": "039b5b16-b1f0-48bb-e29f-720a7bd09561",
    "papermill": {
     "duration": 0.032114,
     "end_time": "2024-12-16T03:42:31.605436",
     "exception": false,
     "start_time": "2024-12-16T03:42:31.573322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>role</th>\n",
       "      <th>type</th>\n",
       "      <th>demographic</th>\n",
       "      <th>description</th>\n",
       "      <th>units</th>\n",
       "      <th>missing_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UID</td>\n",
       "      <td>ID</td>\n",
       "      <td>Integer</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product ID</td>\n",
       "      <td>ID</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Type</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Air temperature</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>K</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Process temperature</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>K</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rotational speed</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Integer</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>rpm</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Torque</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Nm</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tool wear</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Integer</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>min</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Machine failure</td>\n",
       "      <td>Target</td>\n",
       "      <td>Integer</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TWF</td>\n",
       "      <td>Target</td>\n",
       "      <td>Integer</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HDF</td>\n",
       "      <td>Target</td>\n",
       "      <td>Integer</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PWF</td>\n",
       "      <td>Target</td>\n",
       "      <td>Integer</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>OSF</td>\n",
       "      <td>Target</td>\n",
       "      <td>Integer</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RNF</td>\n",
       "      <td>Target</td>\n",
       "      <td>Integer</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name     role         type demographic description units  \\\n",
       "0                   UID       ID      Integer        None        None  None   \n",
       "1            Product ID       ID  Categorical        None        None  None   \n",
       "2                  Type  Feature  Categorical        None        None  None   \n",
       "3       Air temperature  Feature   Continuous        None        None     K   \n",
       "4   Process temperature  Feature   Continuous        None        None     K   \n",
       "5      Rotational speed  Feature      Integer        None        None   rpm   \n",
       "6                Torque  Feature   Continuous        None        None    Nm   \n",
       "7             Tool wear  Feature      Integer        None        None   min   \n",
       "8       Machine failure   Target      Integer        None        None  None   \n",
       "9                   TWF   Target      Integer        None        None  None   \n",
       "10                  HDF   Target      Integer        None        None  None   \n",
       "11                  PWF   Target      Integer        None        None  None   \n",
       "12                  OSF   Target      Integer        None        None  None   \n",
       "13                  RNF   Target      Integer        None        None  None   \n",
       "\n",
       "   missing_values  \n",
       "0              no  \n",
       "1              no  \n",
       "2              no  \n",
       "3              no  \n",
       "4              no  \n",
       "5              no  \n",
       "6              no  \n",
       "7              no  \n",
       "8              no  \n",
       "9              no  \n",
       "10             no  \n",
       "11             no  \n",
       "12             no  \n",
       "13             no  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variable information\n",
    "ai4i_2020_predictive_maintenance_dataset.variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d000466",
   "metadata": {
    "id": "m89CZLgsd2Y_",
    "papermill": {
     "duration": 0.010342,
     "end_time": "2024-12-16T03:42:31.626426",
     "exception": false,
     "start_time": "2024-12-16T03:42:31.616084",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Get the target columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04b6b004",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T03:42:31.649897Z",
     "iopub.status.busy": "2024-12-16T03:42:31.649490Z",
     "iopub.status.idle": "2024-12-16T03:42:31.654932Z",
     "shell.execute_reply": "2024-12-16T03:42:31.653823Z"
    },
    "id": "iq25p5JZdkDY",
    "papermill": {
     "duration": 0.020244,
     "end_time": "2024-12-16T03:42:31.657421",
     "exception": false,
     "start_time": "2024-12-16T03:42:31.637177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = y['Machine failure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4eee7076",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T03:42:31.681546Z",
     "iopub.status.busy": "2024-12-16T03:42:31.681049Z",
     "iopub.status.idle": "2024-12-16T03:42:31.698985Z",
     "shell.execute_reply": "2024-12-16T03:42:31.697662Z"
    },
    "id": "qb2KjMy_dnzM",
    "outputId": "3a80a7f6-d25b-44e1-921a-80f1338aadfc",
    "papermill": {
     "duration": 0.03285,
     "end_time": "2024-12-16T03:42:31.701641",
     "exception": false,
     "start_time": "2024-12-16T03:42:31.668791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Machine failure\n",
       "0    9661\n",
       "1     339\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9abf29",
   "metadata": {
    "id": "MtW7wBRSeba-",
    "papermill": {
     "duration": 0.010563,
     "end_time": "2024-12-16T03:42:31.723332",
     "exception": false,
     "start_time": "2024-12-16T03:42:31.712769",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Preprocess features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af3d4622",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T03:42:31.747631Z",
     "iopub.status.busy": "2024-12-16T03:42:31.746839Z",
     "iopub.status.idle": "2024-12-16T03:42:31.754555Z",
     "shell.execute_reply": "2024-12-16T03:42:31.753449Z"
    },
    "id": "DZwG98G7doh4",
    "outputId": "9ccf0ad8-f841-4be6-f188-5dcf46cd532a",
    "papermill": {
     "duration": 0.022764,
     "end_time": "2024-12-16T03:42:31.756828",
     "exception": false,
     "start_time": "2024-12-16T03:42:31.734064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Type', 'Air temperature', 'Process temperature', 'Rotational speed',\n",
       "       'Torque', 'Tool wear'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "798f9485",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T03:42:31.780152Z",
     "iopub.status.busy": "2024-12-16T03:42:31.779736Z",
     "iopub.status.idle": "2024-12-16T03:42:31.801535Z",
     "shell.execute_reply": "2024-12-16T03:42:31.800340Z"
    },
    "id": "MSS4MFCfeKYB",
    "outputId": "70d4019e-fa2a-4a0c-eaac-5b02899f4e12",
    "papermill": {
     "duration": 0.036714,
     "end_time": "2024-12-16T03:42:31.804486",
     "exception": false,
     "start_time": "2024-12-16T03:42:31.767772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Type                 10000 non-null  object \n",
      " 1   Air temperature      10000 non-null  float64\n",
      " 2   Process temperature  10000 non-null  float64\n",
      " 3   Rotational speed     10000 non-null  int64  \n",
      " 4   Torque               10000 non-null  float64\n",
      " 5   Tool wear            10000 non-null  int64  \n",
      "dtypes: float64(3), int64(2), object(1)\n",
      "memory usage: 468.9+ KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9cc7c65b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T03:42:31.829417Z",
     "iopub.status.busy": "2024-12-16T03:42:31.829000Z",
     "iopub.status.idle": "2024-12-16T03:42:31.837008Z",
     "shell.execute_reply": "2024-12-16T03:42:31.835720Z"
    },
    "id": "krNbGmWSelum",
    "outputId": "29963327-339c-4065-d12d-d13e32b039b2",
    "papermill": {
     "duration": 0.023307,
     "end_time": "2024-12-16T03:42:31.839199",
     "exception": false,
     "start_time": "2024-12-16T03:42:31.815892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['M', 'L', 'H'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e20f393e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T03:42:31.863745Z",
     "iopub.status.busy": "2024-12-16T03:42:31.863365Z",
     "iopub.status.idle": "2024-12-16T03:42:31.873780Z",
     "shell.execute_reply": "2024-12-16T03:42:31.872561Z"
    },
    "id": "mjfqSM66eSHC",
    "papermill": {
     "duration": 0.025464,
     "end_time": "2024-12-16T03:42:31.876271",
     "exception": false,
     "start_time": "2024-12-16T03:42:31.850807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert categorical to numerical features\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "X['Type'].replace(to_replace=[i for i in X['Type'].unique()],\n",
    "                  value=[i for i in range(3)], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c482f6",
   "metadata": {
    "id": "KOrCZ4bgf5ks",
    "papermill": {
     "duration": 0.010837,
     "end_time": "2024-12-16T03:42:31.898823",
     "exception": false,
     "start_time": "2024-12-16T03:42:31.887986",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5daf4b64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T03:42:31.922711Z",
     "iopub.status.busy": "2024-12-16T03:42:31.922331Z",
     "iopub.status.idle": "2024-12-16T03:42:31.928901Z",
     "shell.execute_reply": "2024-12-16T03:42:31.927794Z"
    },
    "id": "TKCXLYjmem6h",
    "papermill": {
     "duration": 0.021247,
     "end_time": "2024-12-16T03:42:31.931097",
     "exception": false,
     "start_time": "2024-12-16T03:42:31.909850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = [\n",
    "    ('Logistic Regression', LogisticRegression()),  # No random_state\n",
    "    ('K-Nearest Neighbors', KNeighborsClassifier()),  # No random_state\n",
    "    ('Decision Tree', DecisionTreeClassifier(random_state=42)),  # Added random_state\n",
    "    ('Random Forest', RandomForestClassifier(random_state=42)),  # Added random_state\n",
    "    ('AdaBoost', AdaBoostClassifier(random_state=42)),  # Added random_state\n",
    "    ('Gradient Boosting', GradientBoostingClassifier(random_state=42)),  # Added random_state\n",
    "    ('Naive Bayes', GaussianNB()),  # No random_state\n",
    "    ('Neural Network', MLPClassifier(random_state=42))  # Added random_state\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ec11af3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T03:42:31.955008Z",
     "iopub.status.busy": "2024-12-16T03:42:31.954606Z",
     "iopub.status.idle": "2024-12-16T03:42:31.963839Z",
     "shell.execute_reply": "2024-12-16T03:42:31.962789Z"
    },
    "id": "DjNC6FbydSd2",
    "papermill": {
     "duration": 0.023858,
     "end_time": "2024-12-16T03:42:31.966067",
     "exception": false,
     "start_time": "2024-12-16T03:42:31.942209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tuning_params = {\n",
    "    'Logistic Regression': {\n",
    "        'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "        'C': [0.01, 0.1, 1, 10, 100],\n",
    "        'solver': ['lbfgs', 'liblinear', 'saga']\n",
    "    },\n",
    "    'K-Nearest Neighbors': {\n",
    "        'n_neighbors': [3, 5, 7, 9, 11],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "        'max_depth': [None, 10, 20, 30, 40],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [50, 100, 200, 300],\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    'AdaBoost': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 1, 10],\n",
    "        'algorithm': ['SAMME', 'SAMME.R']\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 10]\n",
    "    },\n",
    "    'Naive Bayes': {\n",
    "        'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6]\n",
    "    },\n",
    "    'Neural Network': {\n",
    "        'hidden_layer_sizes': [(50,), (100,), (50, 50)],\n",
    "        'activation': ['relu', 'tanh', 'logistic'],\n",
    "        'solver': ['adam', 'sgd', 'lbfgs'],\n",
    "        'alpha': [0.0001, 0.001, 0.01]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76111678",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T03:42:31.989961Z",
     "iopub.status.busy": "2024-12-16T03:42:31.989573Z",
     "iopub.status.idle": "2024-12-16T03:42:32.009477Z",
     "shell.execute_reply": "2024-12-16T03:42:32.008278Z"
    },
    "id": "gqfPPb28giNq",
    "papermill": {
     "duration": 0.03475,
     "end_time": "2024-12-16T03:42:32.011984",
     "exception": false,
     "start_time": "2024-12-16T03:42:31.977234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, stratify=y_train, train_size=0.8, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edac3b32",
   "metadata": {
    "papermill": {
     "duration": 0.01096,
     "end_time": "2024-12-16T03:42:32.034073",
     "exception": false,
     "start_time": "2024-12-16T03:42:32.023113",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## GA-stacking with Default Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c84e0d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T03:42:32.058804Z",
     "iopub.status.busy": "2024-12-16T03:42:32.058387Z",
     "iopub.status.idle": "2024-12-16T03:42:35.918163Z",
     "shell.execute_reply": "2024-12-16T03:42:35.916647Z"
    },
    "papermill": {
     "duration": 3.882915,
     "end_time": "2024-12-16T03:42:35.928692",
     "exception": false,
     "start_time": "2024-12-16T03:42:32.045777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tuning Models: 100%|██████████| 8/8 [00:03<00:00,  2.08model/s]\n"
     ]
    }
   ],
   "source": [
    "tuned_models, _ = tune_and_evaluate_models(X_train, X_val, y_train, y_val, dict(models), {}, f1_score, mode='grid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd390c0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T03:42:36.002675Z",
     "iopub.status.busy": "2024-12-16T03:42:35.999917Z",
     "iopub.status.idle": "2024-12-16T04:03:50.911294Z",
     "shell.execute_reply": "2024-12-16T04:03:50.908833Z"
    },
    "papermill": {
     "duration": 1274.993394,
     "end_time": "2024-12-16T04:03:50.956074",
     "exception": false,
     "start_time": "2024-12-16T03:42:35.962680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GA-stacking with meta model: Logistic Regression\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [01:02<07:17, 62.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GA-stacking with meta model: K-Nearest Neighbors\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [02:09<06:29, 64.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GA-stacking with meta model: Decision Tree\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [03:09<05:14, 62.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GA-stacking with meta model: Random Forest\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [05:34<06:21, 95.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GA-stacking with meta model: AdaBoost\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [07:01<04:37, 92.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GA-stacking with meta model: Gradient Boosting\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [09:49<03:55, 117.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GA-stacking with meta model: Naive Bayes\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [10:43<01:37, 97.02s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GA-stacking with meta model: Neural Network\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [21:14<00:00, 159.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Summary of Results\n",
      "========================================\n",
      "Meta Model: Logistic Regression\n",
      "  • Precision: 0.7333333333333333\n",
      "  • Recall: 0.6470588235294118\n",
      "  • F1 Score: 0.6875\n",
      "  • F30 Score: 0.647143323539014\n",
      "  • Best Combination: [1 0 0 0 0 1 0 0]\n",
      "\n",
      "Meta Model: K-Nearest Neighbors\n",
      "  • Precision: 0.7058823529411765\n",
      "  • Recall: 0.7058823529411765\n",
      "  • F1 Score: 0.7058823529411765\n",
      "  • F30 Score: 0.7058823529411764\n",
      "  • Best Combination: [0 0 0 0 1 1 0 1]\n",
      "\n",
      "Meta Model: Decision Tree\n",
      "  • Precision: 0.6190476190476191\n",
      "  • Recall: 0.7647058823529411\n",
      "  • F1 Score: 0.6842105263157895\n",
      "  • F30 Score: 0.7645062332745904\n",
      "  • Best Combination: [1 0 0 0 1 1 1 0]\n",
      "\n",
      "Meta Model: Random Forest\n",
      "  • Precision: 0.7352941176470589\n",
      "  • Recall: 0.7352941176470589\n",
      "  • F1 Score: 0.735294117647059\n",
      "  • F30 Score: 0.7352941176470589\n",
      "  • Best Combination: [0 0 0 0 1 1 1 0]\n",
      "\n",
      "Meta Model: AdaBoost\n",
      "  • Precision: 0.7666666666666667\n",
      "  • Recall: 0.6764705882352942\n",
      "  • F1 Score: 0.71875\n",
      "  • F30 Score: 0.6765589291544238\n",
      "  • Best Combination: [0 0 0 0 1 1 1 1]\n",
      "\n",
      "Meta Model: Gradient Boosting\n",
      "  • Precision: 0.7878787878787878\n",
      "  • Recall: 0.7647058823529411\n",
      "  • F1 Score: 0.7761194029850745\n",
      "  • F30 Score: 0.7647308458198674\n",
      "  • Best Combination: [1 0 0 0 1 1 1 0]\n",
      "\n",
      "Meta Model: Naive Bayes\n",
      "  • Precision: 0.4827586206896552\n",
      "  • Recall: 0.8235294117647058\n",
      "  • F1 Score: 0.608695652173913\n",
      "  • F30 Score: 0.8228847282927784\n",
      "  • Best Combination: [0 0 0 0 0 1 0 1]\n",
      "\n",
      "Meta Model: Neural Network\n",
      "  • Precision: 0.7272727272727273\n",
      "  • Recall: 0.7058823529411765\n",
      "  • F1 Score: 0.7164179104477613\n",
      "  • F30 Score: 0.7059053961414161\n",
      "  • Best Combination: [1 0 0 0 1 1 1 1]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "meta_models = [\n",
    "    ('Logistic Regression', LogisticRegression()),  # No random_state\n",
    "    ('K-Nearest Neighbors', KNeighborsClassifier()),  # No random_state\n",
    "    ('Decision Tree', DecisionTreeClassifier(random_state=42)),  # Added random_state\n",
    "    ('Random Forest', RandomForestClassifier(random_state=42)),  # Added random_state\n",
    "    ('AdaBoost', AdaBoostClassifier(random_state=42)),  # Added random_state\n",
    "    ('Gradient Boosting', GradientBoostingClassifier(random_state=42)),  # Added random_state\n",
    "    ('Naive Bayes', GaussianNB()),  # No random_state\n",
    "    ('Neural Network', MLPClassifier(random_state=42))  # Added random_state\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, meta_model in tqdm(meta_models):\n",
    "    print(f\"Running GA-stacking with meta model: {name}\\n{'='*40}\")\n",
    "    solver = ga_stacking(\n",
    "        X_train, y_train, X_val, y_val, tuned_models,\n",
    "        meta_model=meta_model,\n",
    "        num_individuals=10,\n",
    "        max_gen=20,\n",
    "        metric=f1_score,\n",
    "        seed=42,\n",
    "        ga_mode='paper'\n",
    "    )\n",
    "    solver.solve()\n",
    "    \n",
    "    best_combination = solver.best_combination\n",
    "    model = solver.best_model\n",
    "    y_pred = model.predict(X_test)\n",
    "    precision = precision_score(y_pred=y_pred, y_true=y_test)\n",
    "    recall = recall_score(y_pred=y_pred, y_true=y_test)\n",
    "    f30 = (1 + 30 ** 2) * (precision * recall) / ((30 ** 2 * precision) + recall)\n",
    "    f1 = f1_score(y_pred=y_pred, y_true=y_test)\n",
    "\n",
    "    results.append({\n",
    "        \"Meta Model\": name,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1,\n",
    "        \"F30 Score\": f30,\n",
    "        \"Best Combination\": best_combination\n",
    "    })\n",
    "\n",
    "# Print summary of results\n",
    "def print_summary():\n",
    "    print(f\"{'='*40}\\nSummary of Results\\n{'='*40}\")\n",
    "    for result in results:\n",
    "        print(f\"Meta Model: {result['Meta Model']}\\n\"\n",
    "              f\"  • Precision: {result['Precision']}\\n\"\n",
    "              f\"  • Recall: {result['Recall']}\\n\"\n",
    "              f\"  • F1 Score: {result['F1 Score']}\\n\"\n",
    "              f\"  • F30 Score: {result['F30 Score']}\\n\"\n",
    "              f\"  • Best Combination: {result['Best Combination']}\\n\")\n",
    "\n",
    "print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37d03994",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T04:03:51.017226Z",
     "iopub.status.busy": "2024-12-16T04:03:51.016859Z",
     "iopub.status.idle": "2024-12-16T04:03:51.193142Z",
     "shell.execute_reply": "2024-12-16T04:03:51.191411Z"
    },
    "papermill": {
     "duration": 0.2038,
     "end_time": "2024-12-16T04:03:51.198024",
     "exception": false,
     "start_time": "2024-12-16T04:03:50.994224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Model: Logistic Regression\n",
      "\n",
      "Metrics:\n",
      "  • Precision: 0.7\n",
      "  • Recall: 0.20588235294117646\n",
      "  • F1 Score: 0.3181818181818182\n",
      "========================================\n",
      "========================================\n",
      "Model: K-Nearest Neighbors\n",
      "\n",
      "Metrics:\n",
      "  • Precision: 0.5714285714285714\n",
      "  • Recall: 0.11764705882352941\n",
      "  • F1 Score: 0.1951219512195122\n",
      "========================================\n",
      "========================================\n",
      "Model: Decision Tree\n",
      "\n",
      "Metrics:\n",
      "  • Precision: 0.631578947368421\n",
      "  • Recall: 0.7058823529411765\n",
      "  • F1 Score: 0.6666666666666667\n",
      "========================================\n",
      "========================================\n",
      "Model: Random Forest\n",
      "\n",
      "Metrics:\n",
      "  • Precision: 0.8695652173913043\n",
      "  • Recall: 0.5882352941176471\n",
      "  • F1 Score: 0.7017543859649124\n",
      "========================================\n",
      "========================================\n",
      "Model: AdaBoost\n",
      "\n",
      "Metrics:\n",
      "  • Precision: 0.5333333333333333\n",
      "  • Recall: 0.47058823529411764\n",
      "  • F1 Score: 0.5\n",
      "========================================\n",
      "========================================\n",
      "Model: Gradient Boosting\n",
      "\n",
      "Metrics:\n",
      "  • Precision: 0.7241379310344828\n",
      "  • Recall: 0.6176470588235294\n",
      "  • F1 Score: 0.6666666666666667\n",
      "========================================\n",
      "========================================\n",
      "Model: Naive Bayes\n",
      "\n",
      "Metrics:\n",
      "  • Precision: 0.3157894736842105\n",
      "  • Recall: 0.17647058823529413\n",
      "  • F1 Score: 0.22641509433962262\n",
      "========================================\n",
      "========================================\n",
      "Model: Neural Network\n",
      "\n",
      "Metrics:\n",
      "  • Precision: 1.0\n",
      "  • Recall: 0.08823529411764706\n",
      "  • F1 Score: 0.1621621621621622\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "for tuned_model_name, tuned_model in tuned_models.items():\n",
    "    y_pred = tuned_model.predict(X_test)\n",
    "    \n",
    "    # Print model name and its chosen parameters\n",
    "    print(f'{\"=\"*40}\\nModel: {tuned_model_name}\\n')\n",
    "    \n",
    "    # Print metrics with bullet points\n",
    "    print(f'Metrics:\\n'\n",
    "          f'  • Precision: {precision_score(y_pred=y_pred, y_true=y_test)}\\n'\n",
    "          f'  • Recall: {recall_score(y_pred=y_pred, y_true=y_test)}\\n'\n",
    "          f'  • F1 Score: {f1_score(y_pred=y_pred, y_true=y_test)}')\n",
    "    \n",
    "    # Separator between models\n",
    "    print(\"=\"*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b50831",
   "metadata": {
    "id": "YEXX6ZhUhkhK",
    "papermill": {
     "duration": 0.038129,
     "end_time": "2024-12-16T04:03:51.274588",
     "exception": false,
     "start_time": "2024-12-16T04:03:51.236459",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## GA-stacking with Tuned Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a84fea05",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-12-16T04:03:51.317924Z",
     "iopub.status.busy": "2024-12-16T04:03:51.317147Z",
     "iopub.status.idle": "2024-12-16T04:15:06.327339Z",
     "shell.execute_reply": "2024-12-16T04:15:06.324232Z"
    },
    "id": "-waTksVdgrfg",
    "outputId": "eac63624-9e94-4ea6-a48f-47ff9c25f588",
    "papermill": {
     "duration": 675.089445,
     "end_time": "2024-12-16T04:15:06.392189",
     "exception": false,
     "start_time": "2024-12-16T04:03:51.302744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tuning Models:   0%|          | 0/8 [00:00<?, ?model/s]/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "Tuning Models:  88%|████████▊ | 7/8 [06:12<00:52, 52.01s/model]/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "Tuning Models: 100%|██████████| 8/8 [11:14<00:00, 84.37s/model] \n"
     ]
    }
   ],
   "source": [
    "tuned_models, _ = tune_and_evaluate_models(X_train, X_val, y_train, y_val, dict(models), tuning_params, f1_score, mode='grid', seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f17c8d48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T04:15:06.470531Z",
     "iopub.status.busy": "2024-12-16T04:15:06.470050Z",
     "iopub.status.idle": "2024-12-16T04:42:23.842636Z",
     "shell.execute_reply": "2024-12-16T04:42:23.841319Z"
    },
    "id": "xxlX8xgXeU0l",
    "papermill": {
     "duration": 1637.466426,
     "end_time": "2024-12-16T04:42:23.913955",
     "exception": false,
     "start_time": "2024-12-16T04:15:06.447529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GA-stacking with meta model: Logistic Regression\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [02:01<14:13, 121.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GA-stacking with meta model: K-Nearest Neighbors\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [04:31<13:49, 138.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GA-stacking with meta model: Decision Tree\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [06:44<11:19, 135.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GA-stacking with meta model: Random Forest\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [10:00<10:37, 159.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GA-stacking with meta model: AdaBoost\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [12:21<07:38, 152.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GA-stacking with meta model: Gradient Boosting\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [16:06<05:54, 177.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GA-stacking with meta model: Naive Bayes\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [18:05<02:38, 158.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GA-stacking with meta model: Neural Network\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [27:17<00:00, 204.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Summary of Results\n",
      "========================================\n",
      "Meta Model: Logistic Regression\n",
      "  • Precision: 0.8\n",
      "  • Recall: 0.7058823529411765\n",
      "  • F1 Score: 0.7500000000000001\n",
      "  • F30 Score: 0.7059745347698335\n",
      "  • Best Combination: [0 0 0 0 1 1 0 0]\n",
      "\n",
      "Meta Model: K-Nearest Neighbors\n",
      "  • Precision: 0.7857142857142857\n",
      "  • Recall: 0.6470588235294118\n",
      "  • F1 Score: 0.7096774193548386\n",
      "  • F30 Score: 0.6471855818205564\n",
      "  • Best Combination: [1 1 1 1 1 1 0 0]\n",
      "\n",
      "Meta Model: Decision Tree\n",
      "  • Precision: 0.7741935483870968\n",
      "  • Recall: 0.7058823529411765\n",
      "  • F1 Score: 0.7384615384615385\n",
      "  • F30 Score: 0.7059514870555972\n",
      "  • Best Combination: [0 0 1 1 1 1 1 0]\n",
      "\n",
      "Meta Model: Random Forest\n",
      "  • Precision: 0.8275862068965517\n",
      "  • Recall: 0.7058823529411765\n",
      "  • F1 Score: 0.7619047619047619\n",
      "  • F30 Score: 0.70599758398903\n",
      "  • Best Combination: [1 0 0 1 0 1 0 0]\n",
      "\n",
      "Meta Model: AdaBoost\n",
      "  • Precision: 0.7741935483870968\n",
      "  • Recall: 0.7058823529411765\n",
      "  • F1 Score: 0.7384615384615385\n",
      "  • F30 Score: 0.7059514870555972\n",
      "  • Best Combination: [0 1 0 0 0 1 0 0]\n",
      "\n",
      "Meta Model: Gradient Boosting\n",
      "  • Precision: 0.7741935483870968\n",
      "  • Recall: 0.7058823529411765\n",
      "  • F1 Score: 0.7384615384615385\n",
      "  • F30 Score: 0.7059514870555972\n",
      "  • Best Combination: [0 0 1 1 1 1 1 0]\n",
      "\n",
      "Meta Model: Naive Bayes\n",
      "  • Precision: 0.7741935483870968\n",
      "  • Recall: 0.7058823529411765\n",
      "  • F1 Score: 0.7384615384615385\n",
      "  • F30 Score: 0.7059514870555972\n",
      "  • Best Combination: [0 0 1 1 1 1 1 0]\n",
      "\n",
      "Meta Model: Neural Network\n",
      "  • Precision: 0.7419354838709677\n",
      "  • Recall: 0.6764705882352942\n",
      "  • F1 Score: 0.7076923076923077\n",
      "  • F30 Score: 0.6765368417616141\n",
      "  • Best Combination: [1 1 1 1 1 1 0 0]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "meta_models = [\n",
    "    ('Logistic Regression', LogisticRegression()),  # No random_state\n",
    "    ('K-Nearest Neighbors', KNeighborsClassifier()),  # No random_state\n",
    "    ('Decision Tree', DecisionTreeClassifier(random_state=42)),  # Added random_state\n",
    "    ('Random Forest', RandomForestClassifier(random_state=42)),  # Added random_state\n",
    "    ('AdaBoost', AdaBoostClassifier(random_state=42)),  # Added random_state\n",
    "    ('Gradient Boosting', GradientBoostingClassifier(random_state=42)),  # Added random_state\n",
    "    ('Naive Bayes', GaussianNB()),  # No random_state\n",
    "    ('Neural Network', MLPClassifier(random_state=42))  # Added random_state\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, meta_model in tqdm(meta_models):\n",
    "    print(f\"Running GA-stacking with meta model: {name}\\n{'='*40}\")\n",
    "    solver = ga_stacking(\n",
    "        X_train, y_train, X_val, y_val, tuned_models,\n",
    "        meta_model=meta_model,\n",
    "        num_individuals=10,\n",
    "        max_gen=20,\n",
    "        metric=f1_score,\n",
    "        seed=42,\n",
    "        ga_mode='paper'\n",
    "    )\n",
    "    solver.solve()\n",
    "    \n",
    "    best_combination = solver.best_combination\n",
    "    model = solver.best_model\n",
    "    y_pred = model.predict(X_test)\n",
    "    precision = precision_score(y_pred=y_pred, y_true=y_test)\n",
    "    recall = recall_score(y_pred=y_pred, y_true=y_test)\n",
    "    f30 = (1 + 30 ** 2) * (precision * recall) / ((30 ** 2 * precision) + recall)\n",
    "    f1 = f1_score(y_pred=y_pred, y_true=y_test)\n",
    "\n",
    "    results.append({\n",
    "        \"Meta Model\": name,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1,\n",
    "        \"F30 Score\": f30,\n",
    "        \"Best Combination\": best_combination\n",
    "    })\n",
    "\n",
    "# Print summary of results\n",
    "def print_summary():\n",
    "    print(f\"{'='*40}\\nSummary of Results\\n{'='*40}\")\n",
    "    for result in results:\n",
    "        print(f\"Meta Model: {result['Meta Model']}\\n\"\n",
    "              f\"  • Precision: {result['Precision']}\\n\"\n",
    "              f\"  • Recall: {result['Recall']}\\n\"\n",
    "              f\"  • F1 Score: {result['F1 Score']}\\n\"\n",
    "              f\"  • F30 Score: {result['F30 Score']}\\n\"\n",
    "              f\"  • Best Combination: {result['Best Combination']}\\n\")\n",
    "\n",
    "print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "355897a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T04:42:23.977210Z",
     "iopub.status.busy": "2024-12-16T04:42:23.976281Z",
     "iopub.status.idle": "2024-12-16T04:42:24.209743Z",
     "shell.execute_reply": "2024-12-16T04:42:24.206265Z"
    },
    "papermill": {
     "duration": 0.26095,
     "end_time": "2024-12-16T04:42:24.213925",
     "exception": false,
     "start_time": "2024-12-16T04:42:23.952975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Model: Logistic Regression\n",
      "\n",
      "Chosen Parameters:\n",
      "  • penalty: l1\n",
      "  • C: 100\n",
      "  • solver: liblinear\n",
      "\n",
      "Metrics:\n",
      "  • Precision: 0.7777777777777778\n",
      "  • Recall: 0.20588235294117646\n",
      "  • F1 Score: 0.3255813953488372\n",
      "========================================\n",
      "========================================\n",
      "Model: K-Nearest Neighbors\n",
      "\n",
      "Chosen Parameters:\n",
      "  • n_neighbors: 3\n",
      "  • weights: distance\n",
      "  • metric: manhattan\n",
      "\n",
      "Metrics:\n",
      "  • Precision: 0.4666666666666667\n",
      "  • Recall: 0.20588235294117646\n",
      "  • F1 Score: 0.28571428571428564\n",
      "========================================\n",
      "========================================\n",
      "Model: Decision Tree\n",
      "\n",
      "Chosen Parameters:\n",
      "  • criterion: gini\n",
      "  • max_depth: 10\n",
      "  • min_samples_split: 2\n",
      "  • min_samples_leaf: 1\n",
      "\n",
      "Metrics:\n",
      "  • Precision: 0.6857142857142857\n",
      "  • Recall: 0.7058823529411765\n",
      "  • F1 Score: 0.6956521739130436\n",
      "========================================\n",
      "========================================\n",
      "Model: Random Forest\n",
      "\n",
      "Chosen Parameters:\n",
      "  • n_estimators: 300\n",
      "  • criterion: gini\n",
      "  • max_depth: None\n",
      "  • min_samples_split: 5\n",
      "\n",
      "Metrics:\n",
      "  • Precision: 0.8\n",
      "  • Recall: 0.5882352941176471\n",
      "  • F1 Score: 0.6779661016949153\n",
      "========================================\n",
      "========================================\n",
      "Model: AdaBoost\n",
      "\n",
      "Chosen Parameters:\n",
      "  • n_estimators: 200\n",
      "  • learning_rate: 1\n",
      "  • algorithm: SAMME\n",
      "\n",
      "Metrics:\n",
      "  • Precision: 0.5483870967741935\n",
      "  • Recall: 0.5\n",
      "  • F1 Score: 0.5230769230769231\n",
      "========================================\n",
      "========================================\n",
      "Model: Gradient Boosting\n",
      "\n",
      "Chosen Parameters:\n",
      "  • n_estimators: 200\n",
      "  • learning_rate: 0.2\n",
      "  • max_depth: 10\n",
      "\n",
      "Metrics:\n",
      "  • Precision: 0.7741935483870968\n",
      "  • Recall: 0.7058823529411765\n",
      "  • F1 Score: 0.7384615384615385\n",
      "========================================\n",
      "========================================\n",
      "Model: Naive Bayes\n",
      "\n",
      "Chosen Parameters:\n",
      "  • var_smoothing: 1e-09\n",
      "\n",
      "Metrics:\n",
      "  • Precision: 0.3157894736842105\n",
      "  • Recall: 0.17647058823529413\n",
      "  • F1 Score: 0.22641509433962262\n",
      "========================================\n",
      "========================================\n",
      "Model: Neural Network\n",
      "\n",
      "Chosen Parameters:\n",
      "  • hidden_layer_sizes: (100,)\n",
      "  • activation: relu\n",
      "  • solver: adam\n",
      "  • alpha: 0.01\n",
      "\n",
      "Metrics:\n",
      "  • Precision: 1.0\n",
      "  • Recall: 0.23529411764705882\n",
      "  • F1 Score: 0.38095238095238093\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "for tuned_model_name, tuned_model in tuned_models.items():\n",
    "    y_pred = tuned_model.predict(X_test)\n",
    "    \n",
    "    # Print model name and its chosen parameters\n",
    "    print(f'{\"=\"*40}\\nModel: {tuned_model_name}\\n')\n",
    "    \n",
    "    # Extract the chosen parameters for the current model from `tuning_params`\n",
    "    chosen_params = tuning_params.get(tuned_model_name, {})\n",
    "    \n",
    "    # Print only the chosen parameters\n",
    "    if chosen_params:\n",
    "        print(\"Chosen Parameters:\")\n",
    "        for param, values in chosen_params.items():\n",
    "            print(f'  • {param}: {tuned_model.get_params().get(param, \"Not Set\")}')\n",
    "    \n",
    "    print()  # Newline after parameters\n",
    "    \n",
    "    # Print metrics with bullet points\n",
    "    print(f'Metrics:\\n'\n",
    "          f'  • Precision: {precision_score(y_pred=y_pred, y_true=y_test)}\\n'\n",
    "          f'  • Recall: {recall_score(y_pred=y_pred, y_true=y_test)}\\n'\n",
    "          f'  • F1 Score: {f1_score(y_pred=y_pred, y_true=y_test)}')\n",
    "    \n",
    "    # Separator between models\n",
    "    print(\"=\"*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421ecfe8",
   "metadata": {
    "papermill": {
     "duration": 0.021562,
     "end_time": "2024-12-16T04:42:24.377613",
     "exception": false,
     "start_time": "2024-12-16T04:42:24.356051",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## GA-stacking with Tuned Parameters and SMOTE technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9b86508e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T04:42:24.426033Z",
     "iopub.status.busy": "2024-12-16T04:42:24.425642Z",
     "iopub.status.idle": "2024-12-16T04:42:34.798677Z",
     "shell.execute_reply": "2024-12-16T04:42:34.797093Z"
    },
    "papermill": {
     "duration": 10.402621,
     "end_time": "2024-12-16T04:42:34.802294",
     "exception": false,
     "start_time": "2024-12-16T04:42:24.399673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in /opt/conda/lib/python3.10/site-packages (0.12.4)\r\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (1.14.1)\r\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (1.2.2)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (3.5.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9ec3b0fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T04:42:34.850010Z",
     "iopub.status.busy": "2024-12-16T04:42:34.848868Z",
     "iopub.status.idle": "2024-12-16T04:42:35.052603Z",
     "shell.execute_reply": "2024-12-16T04:42:35.051528Z"
    },
    "papermill": {
     "duration": 0.23065,
     "end_time": "2024-12-16T04:42:35.055032",
     "exception": false,
     "start_time": "2024-12-16T04:42:34.824382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Calculate the class distribution\n",
    "class_counts = y_train.value_counts()\n",
    "\n",
    "# Identify the majority and minority class sizes\n",
    "majority_class_size = class_counts.max()\n",
    "minority_class_size = class_counts.min()\n",
    "\n",
    "# Calculate the desired minority class size (20% of majority class size)\n",
    "desired_minority_class_size = int(0.2 * majority_class_size)\n",
    "\n",
    "# Calculate the number of new samples required for the minority class\n",
    "sampling_strategy = desired_minority_class_size / majority_class_size\n",
    "\n",
    "# Create and apply SMOTE with the custom sampling strategy\n",
    "smote = SMOTE(sampling_strategy=sampling_strategy, random_state=42)\n",
    "\n",
    "X_train_sampled, y_train_sampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7997400c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T04:42:35.101712Z",
     "iopub.status.busy": "2024-12-16T04:42:35.100576Z",
     "iopub.status.idle": "2024-12-16T04:42:39.924426Z",
     "shell.execute_reply": "2024-12-16T04:42:39.923234Z"
    },
    "papermill": {
     "duration": 4.855115,
     "end_time": "2024-12-16T04:42:39.932437",
     "exception": false,
     "start_time": "2024-12-16T04:42:35.077322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tuning Models: 100%|██████████| 8/8 [00:04<00:00,  1.66model/s]\n"
     ]
    }
   ],
   "source": [
    "tuned_models, _ = tune_and_evaluate_models(X_train_sampled, X_val, y_train_sampled, y_val, dict(models), {}, f1_score, mode='grid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f028afc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T04:42:40.052409Z",
     "iopub.status.busy": "2024-12-16T04:42:40.051990Z",
     "iopub.status.idle": "2024-12-16T05:06:16.518127Z",
     "shell.execute_reply": "2024-12-16T05:06:16.513557Z"
    },
    "papermill": {
     "duration": 1416.589452,
     "end_time": "2024-12-16T05:06:16.598251",
     "exception": false,
     "start_time": "2024-12-16T04:42:40.008799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GA-stacking with meta model: Logistic Regression\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [01:21<09:29, 81.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GA-stacking with meta model: K-Nearest Neighbors\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [02:46<08:23, 83.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GA-stacking with meta model: Decision Tree\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [04:04<06:44, 80.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GA-stacking with meta model: Random Forest\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [06:53<07:42, 115.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GA-stacking with meta model: AdaBoost\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [08:15<05:10, 103.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GA-stacking with meta model: Gradient Boosting\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [11:09<04:15, 127.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GA-stacking with meta model: Naive Bayes\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [12:08<01:45, 105.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GA-stacking with meta model: Neural Network\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [23:36<00:00, 177.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Summary of Results\n",
      "========================================\n",
      "Meta Model: Logistic Regression\n",
      "  • Precision: 0.6216216216216216\n",
      "  • Recall: 0.6764705882352942\n",
      "  • F1 Score: 0.6478873239436619\n",
      "  • F30 Score: 0.6764043476841728\n",
      "  • Best Combination: [1 0 0 1 1 0 0 1]\n",
      "\n",
      "Meta Model: K-Nearest Neighbors\n",
      "  • Precision: 0.5789473684210527\n",
      "  • Recall: 0.6470588235294118\n",
      "  • F1 Score: 0.6111111111111113\n",
      "  • F30 Score: 0.6469743455839155\n",
      "  • Best Combination: [1 0 0 1 1 1 1 1]\n",
      "\n",
      "Meta Model: Decision Tree\n",
      "  • Precision: 0.6111111111111112\n",
      "  • Recall: 0.6470588235294118\n",
      "  • F1 Score: 0.6285714285714287\n",
      "  • F30 Score: 0.6470165817991906\n",
      "  • Best Combination: [1 1 1 1 1 1 0 0]\n",
      "\n",
      "Meta Model: Random Forest\n",
      "  • Precision: 0.5945945945945946\n",
      "  • Recall: 0.6470588235294118\n",
      "  • F1 Score: 0.619718309859155\n",
      "  • F30 Score: 0.6469954630022522\n",
      "  • Best Combination: [1 1 0 1 0 0 1 0]\n",
      "\n",
      "Meta Model: AdaBoost\n",
      "  • Precision: 0.6111111111111112\n",
      "  • Recall: 0.6470588235294118\n",
      "  • F1 Score: 0.6285714285714287\n",
      "  • F30 Score: 0.6470165817991906\n",
      "  • Best Combination: [1 1 1 1 1 1 0 0]\n",
      "\n",
      "Meta Model: Gradient Boosting\n",
      "  • Precision: 0.6111111111111112\n",
      "  • Recall: 0.6470588235294118\n",
      "  • F1 Score: 0.6285714285714287\n",
      "  • F30 Score: 0.6470165817991906\n",
      "  • Best Combination: [0 0 1 1 1 1 1 0]\n",
      "\n",
      "Meta Model: Naive Bayes\n",
      "  • Precision: 0.48148148148148145\n",
      "  • Recall: 0.7647058823529411\n",
      "  • F1 Score: 0.5909090909090909\n",
      "  • F30 Score: 0.7642069550466497\n",
      "  • Best Combination: [0 0 0 1 0 0 0 1]\n",
      "\n",
      "Meta Model: Neural Network\n",
      "  • Precision: 0.5945945945945946\n",
      "  • Recall: 0.6470588235294118\n",
      "  • F1 Score: 0.619718309859155\n",
      "  • F30 Score: 0.6469954630022522\n",
      "  • Best Combination: [0 1 0 1 0 1 1 0]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "meta_models = [\n",
    "    ('Logistic Regression', LogisticRegression()),  # No random_state\n",
    "    ('K-Nearest Neighbors', KNeighborsClassifier()),  # No random_state\n",
    "    ('Decision Tree', DecisionTreeClassifier(random_state=42)),  # Added random_state\n",
    "    ('Random Forest', RandomForestClassifier(random_state=42)),  # Added random_state\n",
    "    ('AdaBoost', AdaBoostClassifier(random_state=42)),  # Added random_state\n",
    "    ('Gradient Boosting', GradientBoostingClassifier(random_state=42)),  # Added random_state\n",
    "    ('Naive Bayes', GaussianNB()),  # No random_state\n",
    "    ('Neural Network', MLPClassifier(random_state=42))  # Added random_state\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, meta_model in tqdm(meta_models):\n",
    "    print(f\"Running GA-stacking with meta model: {name}\\n{'='*40}\")\n",
    "    solver = ga_stacking(\n",
    "        X_train_sampled, y_train_sampled, X_val, y_val, tuned_models,\n",
    "        meta_model=meta_model,\n",
    "        num_individuals=10,\n",
    "        max_gen=20,\n",
    "        metric=f1_score,\n",
    "        seed=42,\n",
    "        ga_mode='paper'\n",
    "    )\n",
    "    solver.solve()\n",
    "    \n",
    "    best_combination = solver.best_combination\n",
    "    model = solver.best_model\n",
    "    y_pred = model.predict(X_test)\n",
    "    precision = precision_score(y_pred=y_pred, y_true=y_test)\n",
    "    recall = recall_score(y_pred=y_pred, y_true=y_test)\n",
    "    f30 = (1 + 30 ** 2) * (precision * recall) / ((30 ** 2 * precision) + recall)\n",
    "    f1 = f1_score(y_pred=y_pred, y_true=y_test)\n",
    "\n",
    "    results.append({\n",
    "        \"Meta Model\": name,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1,\n",
    "        \"F30 Score\": f30,\n",
    "        \"Best Combination\": best_combination\n",
    "    })\n",
    "\n",
    "# Print summary of results\n",
    "def print_summary():\n",
    "    print(f\"{'='*40}\\nSummary of Results\\n{'='*40}\")\n",
    "    for result in results:\n",
    "        print(f\"Meta Model: {result['Meta Model']}\\n\"\n",
    "              f\"  • Precision: {result['Precision']}\\n\"\n",
    "              f\"  • Recall: {result['Recall']}\\n\"\n",
    "              f\"  • F1 Score: {result['F1 Score']}\\n\"\n",
    "              f\"  • F30 Score: {result['F30 Score']}\\n\"\n",
    "              f\"  • Best Combination: {result['Best Combination']}\\n\")\n",
    "\n",
    "print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f1f734c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T05:06:16.682892Z",
     "iopub.status.busy": "2024-12-16T05:06:16.681774Z",
     "iopub.status.idle": "2024-12-16T05:06:16.875587Z",
     "shell.execute_reply": "2024-12-16T05:06:16.873166Z"
    },
    "papermill": {
     "duration": 0.242224,
     "end_time": "2024-12-16T05:06:16.882297",
     "exception": false,
     "start_time": "2024-12-16T05:06:16.640073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Model: Logistic Regression\n",
      "\n",
      "Chosen Parameters:\n",
      "  • penalty: l2\n",
      "  • C: 1.0\n",
      "  • solver: lbfgs\n",
      "\n",
      "Metrics:\n",
      "  • Precision: 0.3548387096774194\n",
      "  • Recall: 0.6470588235294118\n",
      "  • F1 Score: 0.4583333333333333\n",
      "========================================\n",
      "========================================\n",
      "Model: K-Nearest Neighbors\n",
      "\n",
      "Chosen Parameters:\n",
      "  • n_neighbors: 5\n",
      "  • weights: uniform\n",
      "  • metric: minkowski\n",
      "\n",
      "Metrics:\n",
      "  • Precision: 0.23943661971830985\n",
      "  • Recall: 0.5\n",
      "  • F1 Score: 0.32380952380952377\n",
      "========================================\n",
      "========================================\n",
      "Model: Decision Tree\n",
      "\n",
      "Chosen Parameters:\n",
      "  • criterion: gini\n",
      "  • max_depth: None\n",
      "  • min_samples_split: 2\n",
      "  • min_samples_leaf: 1\n",
      "\n",
      "Metrics:\n",
      "  • Precision: 0.39655172413793105\n",
      "  • Recall: 0.6764705882352942\n",
      "  • F1 Score: 0.5\n",
      "========================================\n",
      "========================================\n",
      "Model: Random Forest\n",
      "\n",
      "Chosen Parameters:\n",
      "  • n_estimators: 100\n",
      "  • criterion: gini\n",
      "  • max_depth: None\n",
      "  • min_samples_split: 2\n",
      "\n",
      "Metrics:\n",
      "  • Precision: 0.5945945945945946\n",
      "  • Recall: 0.6470588235294118\n",
      "  • F1 Score: 0.619718309859155\n",
      "========================================\n",
      "========================================\n",
      "Model: AdaBoost\n",
      "\n",
      "Chosen Parameters:\n",
      "  • n_estimators: 50\n",
      "  • learning_rate: 1.0\n",
      "  • algorithm: SAMME.R\n",
      "\n",
      "Metrics:\n",
      "  • Precision: 0.36363636363636365\n",
      "  • Recall: 0.5882352941176471\n",
      "  • F1 Score: 0.44943820224719105\n",
      "========================================\n",
      "========================================\n",
      "Model: Gradient Boosting\n",
      "\n",
      "Chosen Parameters:\n",
      "  • n_estimators: 100\n",
      "  • learning_rate: 0.1\n",
      "  • max_depth: 3\n",
      "\n",
      "Metrics:\n",
      "  • Precision: 0.5909090909090909\n",
      "  • Recall: 0.7647058823529411\n",
      "  • F1 Score: 0.6666666666666667\n",
      "========================================\n",
      "========================================\n",
      "Model: Naive Bayes\n",
      "\n",
      "Chosen Parameters:\n",
      "  • var_smoothing: 1e-09\n",
      "\n",
      "Metrics:\n",
      "  • Precision: 0.24444444444444444\n",
      "  • Recall: 0.3235294117647059\n",
      "  • F1 Score: 0.27848101265822783\n",
      "========================================\n",
      "========================================\n",
      "Model: Neural Network\n",
      "\n",
      "Chosen Parameters:\n",
      "  • hidden_layer_sizes: (100,)\n",
      "  • activation: relu\n",
      "  • solver: adam\n",
      "  • alpha: 0.0001\n",
      "\n",
      "Metrics:\n",
      "  • Precision: 0.9090909090909091\n",
      "  • Recall: 0.29411764705882354\n",
      "  • F1 Score: 0.4444444444444445\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "for tuned_model_name, tuned_model in tuned_models.items():\n",
    "    y_pred = tuned_model.predict(X_test)\n",
    "    \n",
    "    # Print model name and its chosen parameters\n",
    "    print(f'{\"=\"*40}\\nModel: {tuned_model_name}\\n')\n",
    "    \n",
    "    # Extract the chosen parameters for the current model from `tuning_params`\n",
    "    chosen_params = tuning_params.get(tuned_model_name, {})\n",
    "    \n",
    "    # Print only the chosen parameters\n",
    "    if chosen_params:\n",
    "        print(\"Chosen Parameters:\")\n",
    "        for param, values in chosen_params.items():\n",
    "            print(f'  • {param}: {tuned_model.get_params().get(param, \"Not Set\")}')\n",
    "    \n",
    "    print()  # Newline after parameters\n",
    "    \n",
    "    # Print metrics with bullet points\n",
    "    print(f'Metrics:\\n'\n",
    "          f'  • Precision: {precision_score(y_pred=y_pred, y_true=y_test)}\\n'\n",
    "          f'  • Recall: {recall_score(y_pred=y_pred, y_true=y_test)}\\n'\n",
    "          f'  • F1 Score: {f1_score(y_pred=y_pred, y_true=y_test)}')\n",
    "    \n",
    "    # Separator between models\n",
    "    print(\"=\"*40)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30804,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5049.948079,
   "end_time": "2024-12-16T05:06:19.586101",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-16T03:42:09.638022",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
